{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9edf6b43-5c77-43f5-a179-9986fc68abf8",
   "metadata": {},
   "source": [
    "# Esame di Metodi Numerici - 6 Luglio 2023\n",
    "## Turno II -- Ore 11.45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dd546-5e8d-4dde-ab61-51251c05bad2",
   "metadata": {},
   "source": [
    "## Esercizio 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378dc3b4-702c-4e2f-b388-fc5275db9a75",
   "metadata": {},
   "source": [
    "Nel file ``Test_II.mat`` sono memorizzate le matrici A1, A2 ed A3 ed i vettori b1,b2,b3. Risolvere i 3 sistemi lineari aventi ciascuno di essi come matrice dei coefficienti A1 e termine noto b1, A2 e termine noto b2, A3 e terimine noto b3  utilizzando il metodo più adatto per ciascuno di essi e  commentare i risultati ottenuti  giustificandoli alla luce della teoria.\n",
    "Verificare se le matrici sono malcondizionate, dire teoricamente cosa questo implica e verificarlo sperimentalmente.\n",
    "\n",
    "\n",
    "Per la lettura dei dati procedere nel seguente modo:\n",
    "\n",
    "``from scipy.io import loadmat``\n",
    "\n",
    "``import numpy as np``\n",
    "\n",
    "``dati = loadmat('Test_II.mat')``\n",
    "\n",
    "``A1=dati[\"A1\"] ``\n",
    "\n",
    "``A1=A1.astype(float)``\n",
    "\n",
    "`` b1=dati[\"b1\"] ``\n",
    "\n",
    "`` b1=b1.astype(float)``\n",
    "\n",
    "``A2=dati[\"A2\"] ``\n",
    "\n",
    "``A2=A2.astype(float)``\n",
    "\n",
    "`` b2=dati[\"b2\"] ``\n",
    "\n",
    "`` b2=b2.astype(float)``\n",
    "\n",
    "``A3=dati[\"A3\"] ``\n",
    "\n",
    "``A3=A3.astype(float)``\n",
    "\n",
    "`` b3=dati[\"b3\"] ``\n",
    "\n",
    "`` b3=b3.astype(float)``\n",
    "\n",
    "\n",
    "\n",
    "                                                                    Punti 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c837c7a-fc8d-4541-9a7d-0315589b6b77",
   "metadata": {},
   "source": [
    "# Esercizio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602927f7-4366-4f99-9fe6-5fb4ee0ece45",
   "metadata": {},
   "source": [
    "Data l'equazione di 2° grado $$\\frac{1}{2} x^2+2bx-c=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f29d3fc-3800-4a2e-93a1-9c31f878c266",
   "metadata": {},
   "source": [
    "con $b=10^7, c=10^{-i},i=-5,\\cdots,12 $\n",
    "\n",
    "- a) Scrivere le due formule algebriche per ricavare i valori delle 2 soluzioni\n",
    "\n",
    "                                                                                    1 punto\n",
    "- b) Studiare l'indice di condizionamento delle 2 formule algebriche, facendo uso del risultato teorico visto a lezione riguardo l'indice di condizionamento della valutazione di una funzione. (Spiegare il significato di problema mal condizionato) e dire quale delle due formule è malcondizionata. Per quali valori di $c$ il problema risulta ben condizionato?\n",
    "\n",
    "                                                                                    5 punti\n",
    "\n",
    "- c) Nel caso in cui una delle due formule risulti mal condizionata, proporre una soluzione algebricamente equivalente che non sia malcondizionata.\n",
    "\n",
    "                                                                                    3 punti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c8888-3dfe-4ea5-a93b-e0adab565e1b",
   "metadata": {},
   "source": [
    "                                                                        Totale 9 punti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911860d3-45d8-45fc-99f2-bf79c64f1a80",
   "metadata": {},
   "source": [
    "## Domanda intelligenza artificiale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f72b3e-3533-4866-bf02-44fea1b7c825",
   "metadata": {},
   "source": [
    " Limiti delle reti MLP (multilayer Perceptron) ed introduzione delle Reti neurali Convoluzionali. \n",
    "- Architettura di una rete neurale convoluzionale: strati convoluzionali, attivazione non lineare e pooling + parte fully connected.\n",
    "- Loss function per il task della regressione.  Training di una rete. \n",
    "- Cenni sull'algoritmo di backpropagation per il calcolo delle derivate parziale della funzione costo rispetto ai pesi ditutti i layer .\n",
    "- Tecniche di Ottimizzazione: metodo di discesa del gradient batch, metodo del gradiente stocastico (SGD) ,metodo del gradiente stocastico minibatch.\n",
    "                                                                                [7  punti]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5503e7f7-75e3-4f25-adcd-0a4feff1bf4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
